{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traffic-sign classification with Convolutional Neural Network (CNN).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0Y05HUgLDfG"
      },
      "source": [
        "# Traffic-sign classification with Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN3BBrcCnR9A"
      },
      "source": [
        "### **Traffic sign classification task**\n",
        "The task is to categorize $40 \\times 40$ RGB pixelspace input images into 43 possible traffic sign categories: $h: \\mathbb{R}^{4800} \\mapsto \\lbrace 0,1,\\dots,42 \\rbrace$. Due to the three color channels we have a $40 \\times 40 \\times 3 = 4800$ dimensional input.\n",
        "\n",
        "The used dataset consists of more than 50000 images total. A detailed description about the dataset can be found via [this link](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset). An already pre-processed version of the images resized to 40x40 will be used.\n",
        "\n",
        "In this task, convolutional neural networks (CNN-s) usually perform at around 90-95% accuracy. The goal is to try training a network that performs better than humans (98.9% on the original GTSRB)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FodwTpx92Biy"
      },
      "source": [
        "### **import dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2V8m2z7KuYz"
      },
      "source": [
        "# importing the necessary libraries\n",
        "import numpy as np # for linear algebra\n",
        "import tensorflow as tf # for neural models\n",
        "import time # for measuring time\n",
        "import zipfile # for handling zip archives\n",
        "import PIL # for image handling\n",
        "from keras import backend as K\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpsubylfPwiY"
      },
      "source": [
        "import matplotlib.pyplot as plt # for plotting data\n",
        "import plotly\n",
        "import plotly.graph_objs as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opn_AcB72GxI"
      },
      "source": [
        "### get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2YCgvfoLRe0"
      },
      "source": [
        "# downloading & unzipping \"GTSRB 40x40\" dataset\n",
        "!gdown https://drive.google.com/uc?id=1yAe6Qjdpsw2PNcU0fxa2Ak8_JyKKPtyj\n",
        "local_zip = '/content/GTSRB_40x40.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncKSAO4w5BGq"
      },
      "source": [
        "# definitions\n",
        "IMG_SIZE = (40, 40)\n",
        "IMG_SHAPE = (40, 40, 3)\n",
        "NOF_CLASSES = 43\n",
        "\n",
        "TRAIN_SET_PATH = '/content/GTSRB_40x40/training_set_40x40'\n",
        "TRAIN_SET_SIZE = 39209\n",
        "TRAIN_BATCH_SIZE = 256\n",
        "\n",
        "DEV_RATIO = 0.1  # 3920 dev images are enough\n",
        "DEV_BATCH_SIZE = 256\n",
        "\n",
        "TEST_SET_PATH = '/content/GTSRB_40x40/test_set_40x40'\n",
        "TEST_SET_SIZE = 12630\n",
        "TEST_BATCH_SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQocFouIKRhJ"
      },
      "source": [
        "def plot_images(images, true_labels=None, predicted_labels=None):\n",
        "    assert isinstance(images, (list, tuple, np.ndarray))\n",
        "    class_names = ['SL 20km/h', 'SL 30km/h', 'SL 50km/h', 'SL 60km/h', 'SL 70km/h', 'SL 80km/h', 'End of SL 80km/h', 'SL 100km/h', 'SL 120km/h', 'No passing',\n",
        "                   'No passing over 3.5t', 'Right-of-way', 'Priority road', 'Yield', 'Stop', 'No vehicles', 'Prohibited over 3.5t', 'No entry', 'General caution', 'Dangerous curve left',\n",
        "                   'Dangerous curve right', 'Double curve', 'Bumpy road', 'Slippery road', 'Road narrows (right)', 'Road work', 'Traffic signals', 'Pedestrians', 'Children crossing', 'Bicycles crossing',\n",
        "                   'Beware of ice/snow', 'Wild animals crossing', 'End of all s&p limits', 'Turn right ahead', 'Turn left ahead', 'Ahead only', 'Go straight or right', 'Go straight or left',\n",
        "                   'Keep right', 'Keep left', 'Roundabout mandatory', 'End of no passing', 'End no passing (3.5t)']\n",
        "    if true_labels is not None:\n",
        "        assert len(images) == len(true_labels)\n",
        "        true_label_idxs = true_labels.ravel().tolist()\n",
        "        true_titles = [class_names[i] for i in true_label_idxs]\n",
        "    if predicted_labels is not None:\n",
        "        assert len(images) == len(predicted_labels)\n",
        "        pred_label_idxs = predicted_labels.ravel().tolist()\n",
        "        pred_titles = [class_names[i] for i in pred_label_idxs]\n",
        "    \n",
        "    cols = min(10, len(images))\n",
        "    rows = 1 + (len(images)-1)//cols\n",
        "    plt.figure(figsize=(1.3*cols, 1.3*rows))\n",
        "    for n, image in enumerate(images):\n",
        "        plt.subplot(rows, cols, n+1)\n",
        "        plt.xticks([], [])\n",
        "        plt.yticks([], [])\n",
        "        if predicted_labels is None:\n",
        "            if true_labels is not None:  # case 1 - only true labels\n",
        "                plt.xlabel(f'{true_titles[n]}', size=14, c='black')\n",
        "        else:\n",
        "            if true_labels is not None:  # case 2 - both true and predicted labels\n",
        "                plt.xlabel(f'{pred_titles[n]}', size=14, c='green' if true_label_idxs[n]==pred_label_idxs[n] else 'red')\n",
        "            else:                        # case 3 - only predicted labels\n",
        "                plt.xlabel(f'{pred_titles[n]}', size=14, c='blue')\n",
        "        plt.imshow(image)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABWB3nF961cD"
      },
      "source": [
        "# original image\n",
        "img_arr = np.array(PIL.Image.open('/content/GTSRB_40x40/training_set_40x40/00000/00000_00000.ppm'))\n",
        "img_arr = np.expand_dims(img_arr, axis=0)\n",
        "print(img_arr.shape)\n",
        "plot_images(img_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYi-RfKHFYxn"
      },
      "source": [
        "# flow training images in batches using train_datagen generator\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=DEV_RATIO)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_SET_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    class_mode='sparse',\n",
        "    subset='training') # set as training data\n",
        "\n",
        "dev_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_SET_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=DEV_BATCH_SIZE,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False,\n",
        "    subset='validation') # set as dev data\n",
        "\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    TEST_SET_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=TEST_BATCH_SIZE,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EU4J4uo99Eu"
      },
      "source": [
        "augmented_train_datagen = tf.keras.preprocessing.image.ImageDataGenerator( rescale=1./255, validation_split=DEV_RATIO,\n",
        "                                           rotation_range=15,\n",
        "                                           width_shift_range=0.3,\n",
        "                                           height_shift_range=0.3,\n",
        "                                           shear_range=0.2,\n",
        "                                           zoom_range=[0.8, 1.5],\n",
        "                                           horizontal_flip=False,\n",
        "                                           vertical_flip=False,\n",
        "                                           fill_mode='nearest',\n",
        "                                           data_format='channels_last',\n",
        "                                           brightness_range=[0.5, 1.5])\n",
        "\n",
        "\n",
        "augmented_train_generator = augmented_train_datagen.flow_from_directory(\n",
        "    TRAIN_SET_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    class_mode='sparse',\n",
        "    subset='training') # set as training data\n",
        "\n",
        "augmented_dev_generator = augmented_train_datagen.flow_from_directory(\n",
        "    TRAIN_SET_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=DEV_BATCH_SIZE,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False,\n",
        "    subset='validation') # set as dev data\n",
        "\n",
        "augmented_test_generator = tf.keras.preprocessing.image.ImageDataGenerator( rescale=1./255,\n",
        "                                           rotation_range=15,\n",
        "                                           width_shift_range=0.3,\n",
        "                                           height_shift_range=0.3,\n",
        "                                           shear_range=0.2,\n",
        "                                           zoom_range=[0.8, 1.5],\n",
        "                                           horizontal_flip=False,\n",
        "                                           vertical_flip=False,\n",
        "                                           fill_mode='nearest',\n",
        "                                           data_format='channels_last',\n",
        "                                           brightness_range=[0.5, 1.5]).flow_from_directory(\n",
        "    TEST_SET_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=TEST_BATCH_SIZE,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGtgZp7eL2bk"
      },
      "source": [
        "def augment_plot_pics(datagen, orig_img):\n",
        "    dir_augmented_data = \"preview\"\n",
        "    try:\n",
        "        # create preview folder if does not exist, \n",
        "        os.mkdir(dir_augmented_data)\n",
        "    except:\n",
        "        # remove preview folder if exists \n",
        "        # the contents (pictures) in the folder\n",
        "        for item in os.listdir(dir_augmented_data):\n",
        "            os.remove(dir_augmented_data + \"/\" + item)\n",
        "    # convert original image to array\n",
        "    x = tf.keras.preprocessing.image.img_to_array(orig_img)\n",
        "    # reshape (sample, nrow, ncol, 3) 3 = R, G or B\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "\n",
        "    # randomly generate pictures\n",
        "\n",
        "    i = 0\n",
        "    Nplot = 8\n",
        "    for batch in datagen.flow(x,batch_size=1,\n",
        "                          save_to_dir=dir_augmented_data,\n",
        "                          save_prefix=\"pic\",\n",
        "                          save_format='jpeg'):\n",
        "        i += 1\n",
        "        if i > Nplot - 1: # generate 8 pictures \n",
        "            break\n",
        "\n",
        "    # plot the generated data\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "    fig.subplots_adjust(hspace=0.02,wspace=0.01,\n",
        "                    left=0,right=1,bottom=0, top=1)\n",
        "    # original picture\n",
        "    ax = fig.add_subplot(3, 3, 1,xticks=[],yticks=[])        \n",
        "    ax.imshow(orig_img)\n",
        "    ax.set_title(\"original\")\n",
        "    i = 2\n",
        "    for imgnm in os.listdir(dir_augmented_data):\n",
        "        ax = fig.add_subplot(3, 3, i,xticks=[],yticks=[]) \n",
        "        img = tf.keras.preprocessing.image.load_img(dir_augmented_data + \"/\" + imgnm)\n",
        "        ax.imshow(img)\n",
        "        i += 1\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzYOHDGOAWuJ"
      },
      "source": [
        "orig_img = tf.keras.preprocessing.image.load_img(\"/content/GTSRB_40x40/training_set_40x40/00000/00000_00000.ppm\")\n",
        "augment_plot_pics(augmented_train_datagen, orig_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0f_V3XUG58Q"
      },
      "source": [
        "# plotting histogram of the categories\n",
        "bins = np.arange(-0.5, 43, 1)\n",
        "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(24,3))\n",
        "\n",
        "# histogram of the data\n",
        "for ax, setname, setlabels in zip(axs,\n",
        "                                  ['Training', 'Devval', 'Test'],\n",
        "                                  [train_generator.labels, dev_generator.labels, test_generator.labels]):\n",
        "    ax.hist(setlabels, bins=bins, density=True, rwidth=0.9)\n",
        "    ax.set_xlabel('Traffic sign type')\n",
        "    ax.set_xticks(np.arange(0, 43, 2))\n",
        "    ax.set_ylabel('Probability mass')\n",
        "    ax.set_title(f'Histogram of {setlabels.size} {setname} labels')\n",
        "\n",
        "# tweak spacing to prevent clipping of y-label\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRc4Bo3cG1wR"
      },
      "source": [
        "# plotting histogram of the augmented categories\n",
        "bins = np.arange(-0.5, 43, 1)\n",
        "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(24,3))\n",
        "\n",
        "# histogram of the data\n",
        "for ax, setname, setlabels in zip(axs,\n",
        "                                  ['Training', 'Devval', 'Test'],\n",
        "                                  [augmented_train_generator.labels, augmented_dev_generator.labels, augmented_test_generator.labels]):\n",
        "    ax.hist(setlabels, bins=bins, density=True, rwidth=0.9)\n",
        "    ax.set_xlabel('Traffic sign type')\n",
        "    ax.set_xticks(np.arange(0, 43, 2))\n",
        "    ax.set_ylabel('Probability mass')\n",
        "    ax.set_title(f'Histogram of {setlabels.size} {setname} labels')\n",
        "\n",
        "# tweak spacing to prevent clipping of y-label\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5csoppC1pYZ"
      },
      "source": [
        "# Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eHdU6ETHMaH"
      },
      "source": [
        "# defining the model\n",
        "def build_model():\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=IMG_SHAPE, name='LAYER_01_cnv'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', name='LAYER_02_cnv'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Conv2D(128, (3,3), activation='relu', name='LAYER_03_cnv'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3,3), activation='relu', name='LAYER_04_cnv'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(384, activation='relu', name='LAYER_05_fc'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(rate=0.75),\n",
        "        tf.keras.layers.Dense(NOF_CLASSES, activation='softmax', name='LAYER_06_fc')\n",
        "    ])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=tf.keras.optimizers.Adam(lr=0.001, decay=0.001),\n",
        "                  metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyiqhWYtj8YK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8569fc98-9dc1-4933-a041-9f3a9e4c9f29"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "LAYER_01_cnv (Conv2D)        (None, 38, 38, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 38, 38, 64)        256       \n",
            "_________________________________________________________________\n",
            "LAYER_02_cnv (Conv2D)        (None, 36, 36, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 36, 36, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 18, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "LAYER_03_cnv (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "LAYER_04_cnv (Conv2D)        (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "LAYER_05_fc (Dense)          (None, 384)               2408832   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 384)               1536      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "LAYER_06_fc (Dense)          (None, 43)                16555     \n",
            "=================================================================\n",
            "Total params: 2,688,619\n",
            "Trainable params: 2,687,083\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97BZ_a9cHANC"
      },
      "source": [
        "history = model.fit(\n",
        "    augmented_train_generator,\n",
        "    steps_per_epoch = augmented_train_generator.samples // TRAIN_BATCH_SIZE,\n",
        "    validation_data = augmented_dev_generator, \n",
        "    validation_steps = augmented_dev_generator.samples // DEV_BATCH_SIZE,\n",
        "    epochs=2,\n",
        "    verbose=1,\n",
        "    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcPe6LhWMop7"
      },
      "source": [
        "def plot_progress(history=None, main_title=\"\", trivial_model_acc=0.1):\n",
        "    title_text = main_title + \"<br>\" if main_title else \"\"\n",
        "    c = plotly.colors.qualitative.Plotly\n",
        "    min_acc_text = f\"[trivial.acc: {100*trivial_model_acc:.2f}%]\"\n",
        "    fig = go.Figure()\n",
        "    if history is not None:\n",
        "        train_loss = history.history['loss']\n",
        "        valid_loss = history.history['val_loss']\n",
        "        train_acc = history.history['acc']\n",
        "        valid_acc = history.history['val_acc']\n",
        "        if train_acc is not None:\n",
        "            title_text += f\"[train.acc: {100*train_acc[-1]:6.2f}%] \"\n",
        "        if valid_acc is not None:\n",
        "            title_text += f\"[val.acc: <b>{100*valid_acc[-1]:6.2f}%</b>] \"\n",
        "        title_text += min_acc_text\n",
        "        fig.add_trace(go.Scatter(name=\"train loss\", x=list(range(1, len(train_loss)+1)), y=train_loss, mode=\"lines\", line=dict(color=c[2], dash='dash')))\n",
        "        fig.add_trace(go.Scatter(name=\"valid loss\", x=list(range(1, len(valid_loss)+1)), y=valid_loss, mode=\"lines\", line=dict(color=c[2])))\n",
        "        fig.add_trace(go.Scatter(name=\"train ACC\", x=list(range(1, len(train_acc)+1)), y=train_acc, mode=\"lines\", line=dict(color=c[6], dash='dash')))\n",
        "        fig.add_trace(go.Scatter(name=\"valid ACC\", x=list(range(1, len(valid_acc)+1)), y=valid_acc, mode=\"lines\", line=dict(color=c[6]))) \n",
        "    fig.update_layout(title_text=title_text, width=800)\n",
        "    fig.update_xaxes(title=\"epoch\")\n",
        "    fig.update_yaxes(range=[0,1])\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzkoAeeLZXJD"
      },
      "source": [
        "plot_progress(history, trivial_model_acc=0.06)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eVhDr-KKqPD"
      },
      "source": [
        "# devval performance\n",
        "model.evaluate(dev_generator, steps = dev_generator.samples // TEST_BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LndtbhlDXMXT"
      },
      "source": [
        "# freezing layers for transfer learning (transfer from augmented to original distribution)\n",
        "def freeze_model(model):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[-4:]:\n",
        "        layer.trainable = True\n",
        "        \n",
        "    model.layers[-2].rate = 0.0 # lessened dropout rate\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                    optimizer=tf.keras.optimizers.Adam(lr=0.001, decay=0.001),\n",
        "                    metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLldpMA9KXsS"
      },
      "source": [
        "# freee model\n",
        "freeze_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IUcg5e7Hymb"
      },
      "source": [
        "# transfer learn\n",
        "historyTR = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // TRAIN_BATCH_SIZE,\n",
        "    validation_data = dev_generator, \n",
        "    validation_steps = dev_generator.samples // DEV_BATCH_SIZE,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w5WhnpdJDiT"
      },
      "source": [
        "plot_progress(historyTR, trivial_model_acc=0.06)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1Ljy96WQHpe"
      },
      "source": [
        "### Final test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTSRBEzuQM_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3588d4-3ef1-4021-b3fb-9c2d8f5024b9"
      },
      "source": [
        "# test performance\n",
        "model.evaluate(test_generator, steps = test_generator.samples // TEST_BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49/49 [==============================] - 2s 37ms/step - loss: 0.0766 - acc: 0.9798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07663962990045547, 0.9797512888908386]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLkfX6ngrMpE"
      },
      "source": [
        "### Visualizing the convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdRtj1AMQrHY"
      },
      "source": [
        "def plot_convs(model, images, layernum=0, maxchannels=8):\n",
        "    nof_images = images.shape[0]\n",
        "    nof_channels = min(maxchannels, model.layers[layernum].output_shape[-1])\n",
        "    fig, axarr = plt.subplots(nof_images, 1+nof_channels, figsize=(24, 3*nof_images))\n",
        "    layers_outputs = [layer.output for layer in model.layers]\n",
        "    activation_model = tf.keras.models.Model(inputs = model.input, outputs = layers_outputs)\n",
        "    for i in range(nof_images):\n",
        "        axarr[i,0].imshow(images[i])\n",
        "        axarr[i,0].axis('off')\n",
        "        for c in range(nof_channels):\n",
        "            activation = activation_model.predict(images[i:i+1])[layernum]\n",
        "            axarr[i,1+c].imshow(activation[0, : , :, c], cmap='inferno')\n",
        "            axarr[i,1+c].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hdVdIrKxVrK"
      },
      "source": [
        "nof_try_images = 10\n",
        "try_images = train_generator.__getitem__(0)[0][:nof_try_images]\n",
        "try_labels = train_generator.__getitem__(0)[1][:nof_try_images]\n",
        "print(try_labels)\n",
        "plot_convs(model, try_images, layernum=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}